{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "45b61882-497e-4f0e-9fbb-d005aba91d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fcc746e4-115d-4207-9a70-f1ed57e8c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "mapa_condiciones = {\n",
    "    0: \"normal\",\n",
    "    1: \"tuberculosis\",\n",
    "    2: \"neumonia\",\n",
    "    3: \"covid-19\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf096d2-f0e6-4a9b-9fdf-b66998e20c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecffe5e1-ca62-4e79-9b7f-e7d914e7bd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/josejacomeb/Datos1/DatasetsMédicos/ProyectoDIALUNG\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My\\ Drive/ProyectoDIALUNG/\n",
    "#Archivo local \n",
    "#%cd /media/josejacomeb/Datos1/DatasetsMédicos/ProyectoDIALUNG/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c6a79372-9ebd-42a3-94f1-97d4dcb30a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "direccion_dataset_imagenes = \"DIALUNG-Datasets/\"\n",
    "direccion_global = os.getcwd()\n",
    "dir_dataset_train = os.path.join(direccion_global, direccion_dataset_imagenes, \"train_256.hdf5\") \n",
    "dir_dataset_test = os.path.join(direccion_global, direccion_dataset_imagenes, \"test_256.hdf5\")\n",
    "dir_dataset_val = os.path.join(direccion_global, direccion_dataset_imagenes, \"val_256.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "baec3b4b-e5d8-47fa-af87-6b1ba42fb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias de DIALUNG\n",
    "from dialung.utils.creardatasetbinario import crearDatasetBinarioDIALUNG\n",
    "transform = T.Compose([T.CenterCrop(224)])\n",
    "center_crop = T.CenterCrop(224)\n",
    "transform = None\n",
    "dataset_train = crearDatasetBinarioDIALUNG(dir_dataset_train, transform, rgb = False, correccion_gamma = None)\n",
    "dataset_test = crearDatasetBinarioDIALUNG(dir_dataset_test, transform, rgb = False, correccion_gamma = None)\n",
    "dataset_val = crearDatasetBinarioDIALUNG(dir_dataset_val, transform, rgb = False, correccion_gamma = None)\n",
    "\n",
    "dataset_total = ConcatDataset([dataset_train, dataset_test, dataset_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0b079bdc-fb9a-4c9a-9e80-262f1df6962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader #Clase dataloader para cargar en PyTorch los objetos de tipo Dataset\n",
    "batch_size = 512\n",
    "#Creo objetos de tipo DataLoader en lotes de 64 imagenes y barajeados aleatoriamente\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers = 2)\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers = 2)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=batch_size, shuffle=True, num_workers = 2)\n",
    "total_dataloader = DataLoader(dataset_total, batch_size=batch_size, shuffle=True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1a83889a-e34c-4fe8-802c-ba190346a018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ae80e3518f4dce865352f3200fbd4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std: 0.2167416512966156 mean: 0.5674065947532654 max: 0.9339674115180969, min: 0.03992798551917076 total_samples: 501\n"
     ]
    }
   ],
   "source": [
    "import tqdm.notebook as tq\n",
    "dataloader = total_dataloader\n",
    "means = []\n",
    "stds = []\n",
    "maxs = []\n",
    "mins = []\n",
    "total_batches = len(dataloader)\n",
    "for imgs, labels in tq.tqdm(dataloader, total = total_batches):\n",
    "    imgs = center_crop(imgs) \n",
    "    for img in imgs:\n",
    "        img = img/255.0 \n",
    "        means.append(torch.mean(img))\n",
    "        stds.append(torch.std(img))\n",
    "        maxs.append(img.max())\n",
    "        mins.append(img.min())\n",
    "\n",
    "mean = torch.mean(torch.tensor(means))\n",
    "std = torch.mean(torch.tensor(stds))\n",
    "max_value = torch.mean(torch.tensor(maxs))\n",
    "min_value = torch.mean(torch.tensor(mins))\n",
    "total_elements = len(means)\n",
    "print(f\"std: {std} mean: {mean} max: {max_value}, min: {min_value} total_samples: {total_elements}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
